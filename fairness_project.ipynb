{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# references:\n",
    "# https://github.com/fpretto/interpretable_and_fair_ml/blob/master/Model%20Interpretation%20and%20Fairness.ipynb\n",
    "# https://towardsdatascience.com/compas-case-study-fairness-of-a-machine-learning-model-f0f804108751\n",
    "# !pip install https://github.com/adebayoj/fairml/archive/master.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "from fairml import audit_model\n",
    "from fairml import plot_dependencies\n",
    "from sklearn.metrics import confusion_matrix\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# compas model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6150, 53)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('data/compas-scores-two-years.csv')\n",
    "df = df[ df['race'].isin(['African-American', 'Caucasian']) ]\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False positive rate (Black)      :  0.34317548746518106\n",
      "False negative rate (Black)      :  0.37243556023145713\n"
     ]
    }
   ],
   "source": [
    "# score for Black defendants\n",
    "threshold  = 6\n",
    "df_black = df[df['race']==\"African-American\"].copy()\n",
    "df_black['is_med_or_high_risk'] = (df_black['decile_score']>=threshold).astype(int)\n",
    "[[tn , fp],[fn , tp]]  = confusion_matrix(df_black['two_year_recid'], df_black['is_med_or_high_risk'])\n",
    "print(\"False positive rate (Black)      : \", fp/(fp+tn))\n",
    "print(\"False negative rate (Black)      : \", fn/(fn+tp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False positive rate (White)      :  0.14717741935483872\n",
      "False negative rate (White)      :  0.5921325051759835\n"
     ]
    }
   ],
   "source": [
    "# score for White defendants\n",
    "threshold  = 6\n",
    "df_white = df[df['race']==\"Caucasian\"].copy()\n",
    "df_white['is_med_or_high_risk'] = (df_white['decile_score']>=threshold).astype(int)\n",
    "[[tn , fp],[fn , tp]]  = confusion_matrix(df_white['two_year_recid'], df_white['is_med_or_high_risk'])\n",
    "print(\"False positive rate (White)      : \", fp/(fp+tn))\n",
    "print(\"False negative rate (White)      : \", fn/(fn+tp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate predicts recitivism (White)      :  0.39364303178484106\n"
     ]
    }
   ],
   "source": [
    "# recitivism prediction for White defendants\n",
    "threshold  = 6\n",
    "df_white = df[df['race']==\"Caucasian\"].copy()\n",
    "df_white['is_med_or_high_risk'] = (df_white['decile_score']>=threshold).astype(int)\n",
    "[[tn , fp],[fn , tp]]  = confusion_matrix(df_white['two_year_recid'], df_white['is_med_or_high_risk'])\n",
    "print(\"Rate predicts recitivism (White)      : \", (tp +fn)/ (tn + fp + fn + tp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate predicts recitivism (Black)      :  0.5143398268398268\n"
     ]
    }
   ],
   "source": [
    "# recitivism prediction for Black defendants\n",
    "threshold  = 6\n",
    "df_white = df[df['race']==\"African-American\"].copy()\n",
    "df_white['is_med_or_high_risk'] = (df_white['decile_score']>=threshold).astype(int)\n",
    "[[tn , fp],[fn , tp]]  = confusion_matrix(df_white['two_year_recid'], df_white['is_med_or_high_risk'])\n",
    "print(\"Rate predicts recitivism (Black)      : \", (tp +fn)/ (tn + fp + fn + tp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# our models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7214, 53)\n",
      "(6150, 9)\n",
      "(6139, 9)\n",
      "(6118, 9)\n",
      "(6113, 9)\n",
      "(6113, 18)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('data/compas-scores-two-years.csv')\n",
    "print(df.shape)\n",
    "feats = ['race', 'sex', 'age_cat',  'juv_fel_count', 'juv_misd_count', 'juv_other_count', 'priors_count', 'c_charge_degree', 'two_year_recid']\n",
    "df = df[ feats ]\n",
    "df = df[ df['race'].isin(['African-American', 'Caucasian']) ]\n",
    "print(df.shape)\n",
    "for e in feats:\n",
    "    if e.startswith('juv_'):\n",
    "        big_cat = dict(df[e].value_counts())\n",
    "        bigs = [c for c in big_cat if big_cat[c]>=10]\n",
    "        df = df[ df[e].isin(bigs) ]\n",
    "        print(df.shape)\n",
    "        \n",
    "data_model  = pd.concat([\n",
    "                df[ ['priors_count','two_year_recid'] ], \n",
    "                pd.get_dummies(df['race'], drop_first = True, prefix = 'race'),\n",
    "                pd.get_dummies(df['sex'], drop_first = True, prefix = 'sex'),\n",
    "                pd.get_dummies(df['age_cat'], drop_first = True, prefix = 'age_cat'),\n",
    "                pd.get_dummies(df['juv_fel_count'], drop_first = True, prefix = 'juv_fel_count'),\n",
    "                pd.get_dummies(df['juv_misd_count'], drop_first = True, prefix = 'juv_misd_count'),\n",
    "                pd.get_dummies(df['juv_other_count'], drop_first = True, prefix = 'juv_other_count'),\n",
    "                pd.get_dummies(df['c_charge_degree'], drop_first = True, prefix = 'c_charge_degree')\n",
    "                ], axis = 1)\n",
    "print(data_model.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model with all features including 'race' (or unfair model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'xgb' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-fbc7615ec6d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                                     \u001b[0mstratify\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_model\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget_col\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                                                     random_state=42, test_size=0.2)\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mclf_xgb_w_race\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXGBClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'binary:logistic'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m800\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m0.05\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mclf_xgb_w_race\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_metric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"auc\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'xgb' is not defined"
     ]
    }
   ],
   "source": [
    "## Train/Test Split\n",
    "target_col = 'two_year_recid'\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_model.drop([target_col], axis=1), \n",
    "                                                    data_model[target_col], \n",
    "                                                    stratify = data_model[target_col],\n",
    "                                                    random_state=42, test_size=0.2)\n",
    "clf_xgb_w_race = xgb.XGBClassifier(objective = 'binary:logistic', n_estimators= 800, max_depth= 4, learning_rate= 0.05, seed = 42)\n",
    "clf_xgb_w_race.fit(X_train.values, y_train, eval_metric=\"auc\", verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False positive rate (Black)      :  0.3314285714285714\n",
      "False negative rate (Black)      :  0.31754874651810583\n"
     ]
    }
   ],
   "source": [
    "# score for Black defendants\n",
    "X_test_ = X_test[ X_test['race_Caucasian']==0 ]\n",
    "y_test_ = y_test[ X_test['race_Caucasian']==0 ]\n",
    "y_pred_ = clf_xgb_w_race.predict(X_test_.values)\n",
    "[[tn , fp],[fn , tp]]  = confusion_matrix(y_test_, y_pred_)\n",
    "print(\"False positive rate (Black)      : \", fp/(fp+tn))\n",
    "print(\"False negative rate (Black)      : \", fn/(fn+tp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False positive rate (White)      :  0.18360655737704917\n",
      "False negative rate (White)      :  0.5741626794258373\n"
     ]
    }
   ],
   "source": [
    "# score for White defendants\n",
    "X_test_ = X_test[ X_test['race_Caucasian']==1 ]\n",
    "y_test_ = y_test[ X_test['race_Caucasian']==1 ]\n",
    "y_pred_ = clf_xgb_w_race.predict(X_test_.values)\n",
    "[[tn , fp],[fn , tp]]  = confusion_matrix(y_test_, y_pred_)\n",
    "print(\"False positive rate (White)      : \", fp/(fp+tn))\n",
    "print(\"False negative rate (White)      : \", fn/(fn+tp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model without 'race' (or unaware model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.05, max_delta_step=0, max_depth=4,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=800, n_jobs=0, num_parallel_tree=1, random_state=42,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=42,\n",
       "              subsample=1, tree_method='exact', validate_parameters=1,\n",
       "              verbosity=None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Train/Test Split\n",
    "target_col = 'two_year_recid'\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_model.drop([target_col], axis=1), \n",
    "                                                    data_model[target_col], \n",
    "                                                    stratify = data_model[target_col],\n",
    "                                                    random_state=42, test_size=0.2)\n",
    "\n",
    "cols = list(X_train.columns)\n",
    "cols.remove('race_Caucasian')\n",
    "X_train_wo_race = X_train[ cols ]\n",
    "X_test_wo_race = X_test[ cols ]\n",
    "\n",
    "clf_xgb_wo_race = xgb.XGBClassifier(objective = 'binary:logistic', n_estimators= 800, max_depth= 4, learning_rate= 0.05, seed = 42)\n",
    "clf_xgb_wo_race.fit(X_train_wo_race.values, y_train, eval_metric=\"auc\", verbose=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False positive rate (Black)      :  0.31142857142857144\n",
      "False negative rate (Black)      :  0.3565459610027855\n"
     ]
    }
   ],
   "source": [
    "# score for Black defendants\n",
    "X_test_ = X_test_wo_race[ X_test['race_Caucasian']==0 ]\n",
    "y_test_ = y_test[ X_test['race_Caucasian']==0 ]\n",
    "y_pred_ = clf_xgb_wo_race.predict(X_test_.values)\n",
    "[[tn , fp],[fn , tp]]  = confusion_matrix(y_test_, y_pred_)\n",
    "print(\"False positive rate (Black)      : \", fp/(fp+tn))\n",
    "print(\"False negative rate (Black)      : \", fn/(fn+tp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False positive rate (White)      :  0.21639344262295082\n",
      "False negative rate (White)      :  0.5741626794258373\n"
     ]
    }
   ],
   "source": [
    "# score for White defendants\n",
    "X_test_ = X_test_wo_race[ X_test['race_Caucasian']==1 ]\n",
    "y_test_ = y_test[ X_test['race_Caucasian']==1 ]\n",
    "y_pred_ = clf_xgb_wo_race.predict(X_test_.values)\n",
    "[[tn , fp],[fn , tp]]  = confusion_matrix(y_test_, y_pred_)\n",
    "print(\"False positive rate (White)      : \", fp/(fp+tn))\n",
    "print(\"False negative rate (White)      : \", fn/(fn+tp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counter Fairness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reference: https://github.com/fiorenza2/CFFair_Emulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pystan\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from argparse import ArgumentParser, ArgumentTypeError\n",
    "from pathlib import Path\n",
    "# wrapper class for statsmodels linear regression (more stable than SKLearn)\n",
    "class SM_LinearRegression():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        N = X.shape[0]\n",
    "        self.LRFit = sm.OLS(y, np.hstack([X,np.ones(N).reshape(-1,1)]),hasconst=True).fit()\n",
    "        \n",
    "    def predict(self,X):\n",
    "        N = X.shape[0]\n",
    "        return self.LRFit.predict(np.hstack([X,np.ones(N).reshape(-1,1)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7214, 53)\n",
      "(6150, 9)\n",
      "(6139, 9)\n",
      "(6118, 9)\n",
      "(6113, 9)\n",
      "(6113, 18)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('compas-scores-two-years.csv')\n",
    "print(df.shape)\n",
    "feats = ['race', 'sex', 'age_cat',  'juv_fel_count', 'juv_misd_count', 'juv_other_count', 'priors_count', 'c_charge_degree', 'two_year_recid']\n",
    "df = df[ feats ]\n",
    "df = df[ df['race'].isin(['African-American', 'Caucasian']) ]\n",
    "print(df.shape)\n",
    "for e in feats:\n",
    "    if e.startswith('juv_'):\n",
    "        big_cat = dict(df[e].value_counts())\n",
    "        bigs = [c for c in big_cat if big_cat[c]>=10]\n",
    "        df = df[ df[e].isin(bigs) ]\n",
    "        print(df.shape)\n",
    "        \n",
    "data_model  = pd.concat([\n",
    "                df[ ['priors_count','two_year_recid'] ], \n",
    "                pd.get_dummies(df['race'], drop_first = True, prefix = 'race'),\n",
    "                pd.get_dummies(df['sex'], drop_first = True, prefix = 'sex'),\n",
    "                pd.get_dummies(df['age_cat'], drop_first = True, prefix = 'age_cat'),\n",
    "                pd.get_dummies(df['juv_fel_count'], drop_first = True, prefix = 'juv_fel_count'),\n",
    "                pd.get_dummies(df['juv_misd_count'], drop_first = True, prefix = 'juv_misd_count'),\n",
    "                pd.get_dummies(df['juv_other_count'], drop_first = True, prefix = 'juv_other_count'),\n",
    "                pd.get_dummies(df['c_charge_degree'], drop_first = True, prefix = 'c_charge_degree')\n",
    "                ], axis = 1)\n",
    "print(data_model.shape)\n",
    "\n",
    "## Train/Test Split\n",
    "target_col = 'two_year_recid'\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_model.drop([target_col], axis=1), \n",
    "                                                    data_model[target_col], \n",
    "                                                    stratify = data_model[target_col],\n",
    "                                                    random_state=42, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>priors_count</th>\n",
       "      <th>race_Caucasian</th>\n",
       "      <th>sex_Male</th>\n",
       "      <th>age_cat_Greater than 45</th>\n",
       "      <th>age_cat_Less than 25</th>\n",
       "      <th>juv_fel_count_1</th>\n",
       "      <th>juv_fel_count_2</th>\n",
       "      <th>juv_fel_count_3</th>\n",
       "      <th>juv_fel_count_4</th>\n",
       "      <th>juv_misd_count_1</th>\n",
       "      <th>juv_misd_count_2</th>\n",
       "      <th>juv_misd_count_3</th>\n",
       "      <th>juv_other_count_1</th>\n",
       "      <th>juv_other_count_2</th>\n",
       "      <th>juv_other_count_3</th>\n",
       "      <th>juv_other_count_4</th>\n",
       "      <th>c_charge_degree_M</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2232</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3056</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3717</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4702</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      priors_count  race_Caucasian  sex_Male  age_cat_Greater than 45  \\\n",
       "2232             2               0         1                        1   \n",
       "1009             1               1         1                        1   \n",
       "3056             5               0         1                        0   \n",
       "3717             0               1         0                        0   \n",
       "4702             2               0         1                        0   \n",
       "\n",
       "      age_cat_Less than 25  juv_fel_count_1  juv_fel_count_2  juv_fel_count_3  \\\n",
       "2232                     0                0                0                0   \n",
       "1009                     0                0                0                0   \n",
       "3056                     0                0                0                0   \n",
       "3717                     1                0                0                0   \n",
       "4702                     0                0                0                0   \n",
       "\n",
       "      juv_fel_count_4  juv_misd_count_1  juv_misd_count_2  juv_misd_count_3  \\\n",
       "2232                0                 0                 0                 0   \n",
       "1009                0                 0                 0                 0   \n",
       "3056                0                 0                 0                 0   \n",
       "3717                0                 0                 0                 0   \n",
       "4702                0                 0                 0                 0   \n",
       "\n",
       "      juv_other_count_1  juv_other_count_2  juv_other_count_3  \\\n",
       "2232                  0                  0                  0   \n",
       "1009                  0                  0                  0   \n",
       "3056                  0                  0                  0   \n",
       "3717                  0                  0                  0   \n",
       "4702                  0                  0                  0   \n",
       "\n",
       "      juv_other_count_4  c_charge_degree_M  \n",
       "2232                  0                  0  \n",
       "1009                  0                  0  \n",
       "3056                  0                  0  \n",
       "3717                  0                  1  \n",
       "4702                  0                  0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_eps_priors_count = SM_LinearRegression()\n",
    "linear_eps_priors_count.fit(np.vstack((X_train['race_Caucasian'].values.reshape(-1,1),X_test['race_Caucasian'].values.reshape(-1,1))),\n",
    "               list(X_train['priors_count'])  + list(X_test['priors_count']) \n",
    "                           )\n",
    "eps_priors_count_train = list(X_train['priors_count']) - linear_eps_priors_count.predict(X_train['race_Caucasian'].values.reshape(-1,1))\n",
    "eps_priors_count_test = list(X_test['priors_count']) - linear_eps_priors_count.predict(X_test['race_Caucasian'].values.reshape(-1,1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_eps_c_charge_degree_M = SM_LinearRegression()\n",
    "linear_eps_c_charge_degree_M.fit(np.vstack((X_train['race_Caucasian'].values.reshape(-1,1),X_test['race_Caucasian'].values.reshape(-1,1))),\n",
    "               list(X_train['c_charge_degree_M'])  + list(X_test['c_charge_degree_M']) \n",
    "                           )\n",
    "eps_c_charge_degree_M_train = list(X_train['c_charge_degree_M']) - linear_eps_c_charge_degree_M.predict(X_train['race_Caucasian'].values.reshape(-1,1))\n",
    "eps_c_charge_degree_M_test = list(X_test['c_charge_degree_M']) - linear_eps_c_charge_degree_M.predict(X_test['race_Caucasian'].values.reshape(-1,1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on target using abducted latents\n",
    "smlr_L3 = SM_LinearRegression()\n",
    "smlr_L3.fit(np.hstack((eps_priors_count_train.reshape(-1,1),eps_c_charge_degree_M_train.reshape(-1,1))),y_train)#.values.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on test epsilons\n",
    "preds = smlr_L3.predict(np.hstack(( eps_priors_count_test.reshape(-1,1),eps_c_charge_degree_M_test.reshape(-1,1) )))\n",
    "preds = [1 if e>.5 else 0 for e in preds]\n",
    "preds = np.array(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False positive rate (Black)      :  0.1657142857142857\n",
      "False negative rate (Black)      :  0.5626740947075209\n"
     ]
    }
   ],
   "source": [
    "# score for Black defendants\n",
    "y_test_ = y_test[ X_test['race_Caucasian']==0 ]\n",
    "y_pred_ =  preds[ X_test['race_Caucasian']==0 ]\n",
    "[[tn , fp],[fn , tp]]  = confusion_matrix(y_test_, y_pred_)\n",
    "print(\"False positive rate (Black)      : \", fp/(fp+tn))\n",
    "print(\"False negative rate (Black)      : \", fn/(fn+tp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False positive rate (White)      :  0.18688524590163935\n",
      "False negative rate (White)      :  0.5933014354066986\n"
     ]
    }
   ],
   "source": [
    "# score for White defendants\n",
    "y_test_ = y_test[ X_test['race_Caucasian']==1 ]\n",
    "y_pred_ =  preds[ X_test['race_Caucasian']==1 ]\n",
    "[[tn , fp],[fn , tp]]  = confusion_matrix(y_test_, y_pred_)\n",
    "print(\"False positive rate (White)      : \", fp/(fp+tn))\n",
    "print(\"False negative rate (White)      : \", fn/(fn+tp))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
