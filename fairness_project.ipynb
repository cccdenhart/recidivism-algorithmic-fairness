{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix,roc_auc_score,accuracy_score\n",
    "import statsmodels.api as sm\n",
    "import xgboost as xgb\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# wrapper class for statsmodels linear regression (more stable than SKLearn)\n",
    "class SM_LinearRegression():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        N = X.shape[0]\n",
    "        self.LRFit = sm.OLS(y, np.hstack([X,np.ones(N).reshape(-1,1)]),hasconst=True).fit()\n",
    "        \n",
    "    def predict(self,X):\n",
    "        N = X.shape[0]\n",
    "        return self.LRFit.predict(np.hstack([X,np.ones(N).reshape(-1,1)]))\n",
    "    \n",
    "def to_binary(y):\n",
    "    y = [e/max(y) for e in y]\n",
    "    y = [1 if e>.5 else 0 for e in y]\n",
    "    return np.array(y)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [SM_LinearRegression(),\n",
    "               RandomForestClassifier(random_state=42),\n",
    "               LGBMClassifier(seed = 42),\n",
    "               xgb.XGBClassifier(objective = 'binary:logistic', seed = 42)]\n",
    "classifier = classifiers[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compas model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7214, 53)\n",
      "(6150, 53)\n",
      "(6139, 53)\n",
      "(6118, 53)\n",
      "(6113, 53)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('compas-scores-two-years.csv')\n",
    "print(df.shape)\n",
    "df = df[ df['race'].isin(['African-American', 'Caucasian']) ]\n",
    "feats = list(df.columns)\n",
    "print(df.shape)\n",
    "for e in feats:\n",
    "    if e.startswith('juv_'):\n",
    "        big_cat = dict(df[e].value_counts())\n",
    "        bigs = [c for c in big_cat if big_cat[c]>=10]\n",
    "        df = df[ df[e].isin(bigs) ]\n",
    "        print(df.shape)\n",
    "df = df[ [\"race\",\"sex\",\"age_cat\",\"c_charge_degree\",\"two_year_recid\"] ]\n",
    "df.to_csv('compas-scores-two-years_short.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6150, 53)\n",
      "(6139, 53)\n",
      "(6118, 53)\n",
      "(6113, 53)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('compas-scores-two-years.csv')\n",
    "df = df[ df['race'].isin(['African-American', 'Caucasian']) ]\n",
    "feats = list(df.columns)\n",
    "print(df.shape)\n",
    "for e in feats:\n",
    "    if e.startswith('juv_'):\n",
    "        big_cat = dict(df[e].value_counts())\n",
    "        bigs = [c for c in big_cat if big_cat[c]>=10]\n",
    "        df = df[ df[e].isin(bigs) ]\n",
    "        print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False positive rate (Black)      :  0.3417085427135678\n",
      "False negative rate (Black)      :  0.3757995735607676\n",
      "Accuracy (Black)      :   0.6408508317425688\n",
      "AUC (Black)      :   0.6412459418628323\n",
      "\n",
      "False positive rate (White)      :  0.14555256064690028\n",
      "False negative rate (White)      :  0.5945945945945946\n",
      "Accuracy (White)      :   0.6778413736713\n",
      "AUC (White)      :   0.6299264223792527\n",
      "\n",
      "False positive rate Gap: 0.19615598206666754\n",
      "False negative rate Gap: 0.21879502103382703\n"
     ]
    }
   ],
   "source": [
    "# score for Black defendants\n",
    "threshold  = 6\n",
    "df_black = df[df['race']==\"African-American\"].copy()\n",
    "df_black['is_med_or_high_risk'] = (df_black['decile_score']>=threshold).astype(int)\n",
    "[[tn , fp],[fn , tp]]  = confusion_matrix(df_black['two_year_recid'], df_black['is_med_or_high_risk'])\n",
    "print(\"False positive rate (Black)      : \", fp/(fp+tn))\n",
    "print(\"False negative rate (Black)      : \", fn/(fn+tp))\n",
    "print(\"Accuracy (Black)      :  \", accuracy_score(df_black['two_year_recid'], df_black['is_med_or_high_risk']) )\n",
    "print(\"AUC (Black)      :  \", roc_auc_score(df_black['two_year_recid'], df_black['is_med_or_high_risk']) )\n",
    "\n",
    "fpr_black = fp/(fp+tn)\n",
    "fnr_black =  fn/(fn+tp)\n",
    "\n",
    "# score for White defendants\n",
    "threshold  = 6\n",
    "df_white = df[df['race']==\"Caucasian\"].copy()\n",
    "df_white['is_med_or_high_risk'] = (df_white['decile_score']>=threshold).astype(int)\n",
    "[[tn , fp],[fn , tp]]  = confusion_matrix(df_white['two_year_recid'], df_white['is_med_or_high_risk'])\n",
    "print(\"\\nFalse positive rate (White)      : \", fp/(fp+tn))\n",
    "print(\"False negative rate (White)      : \", fn/(fn+tp))\n",
    "print(\"Accuracy (White)      :  \", accuracy_score(df_white['two_year_recid'], df_white['is_med_or_high_risk']) )\n",
    "print(\"AUC (White)      :  \", roc_auc_score(df_white['two_year_recid'], df_white['is_med_or_high_risk']) )\n",
    "\n",
    "fpr_white = fp/(fp+tn)\n",
    "fnr_white =  fn/(fn+tp)\n",
    "\n",
    "print('\\nFalse positive rate Gap:', abs(fpr_black-fpr_white))\n",
    "print('False negative rate Gap:', abs(fnr_black-fnr_white))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model with all features including 'race' (or unfair model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7214, 53)\n",
      "(6150, 9)\n",
      "(6139, 9)\n",
      "(6118, 9)\n",
      "(6113, 9)\n",
      "(6113, 18)\n",
      "False positive rate (Black)      :  0.11428571428571428\n",
      "False negative rate (Black)      :  0.6406685236768802\n",
      "Accuracy (Black)      :   0.6191819464033851\n",
      "AUC (Black)      :   0.6225228810187027\n",
      "\n",
      "False positive rate (White)      :  0.19672131147540983\n",
      "False negative rate (White)      :  0.631578947368421\n",
      "Accuracy (White)      :   0.6264591439688716\n",
      "AUC (White)      :   0.5858498705780846\n",
      "\n",
      "False positive rate Gap: 0.08243559718969555\n",
      "False negative rate Gap: 0.00908957630845919\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('compas-scores-two-years.csv')\n",
    "print(df.shape)\n",
    "feats = ['race', 'sex', 'age_cat',  'juv_fel_count', 'juv_misd_count', 'juv_other_count', 'priors_count', 'c_charge_degree', 'two_year_recid']\n",
    "df = df[ feats ]\n",
    "df = df[ df['race'].isin(['African-American', 'Caucasian']) ]\n",
    "print(df.shape)\n",
    "for e in feats:\n",
    "    if e.startswith('juv_'):\n",
    "        big_cat = dict(df[e].value_counts())\n",
    "        bigs = [c for c in big_cat if big_cat[c]>=10]\n",
    "        df = df[ df[e].isin(bigs) ]\n",
    "        print(df.shape)\n",
    "        \n",
    "data_model  = pd.concat([\n",
    "                df[ ['priors_count','two_year_recid'] ], \n",
    "                pd.get_dummies(df['race'], drop_first = True, prefix = 'race'),\n",
    "                pd.get_dummies(df['sex'], drop_first = True, prefix = 'sex'),\n",
    "                pd.get_dummies(df['age_cat'], drop_first = True, prefix = 'age_cat'),\n",
    "                pd.get_dummies(df['juv_fel_count'], drop_first = True, prefix = 'juv_fel_count'),\n",
    "                pd.get_dummies(df['juv_misd_count'], drop_first = True, prefix = 'juv_misd_count'),\n",
    "                pd.get_dummies(df['juv_other_count'], drop_first = True, prefix = 'juv_other_count'),\n",
    "                pd.get_dummies(df['c_charge_degree'], drop_first = True, prefix = 'c_charge_degree')\n",
    "                ], axis = 1)\n",
    "print(data_model.shape)\n",
    "\n",
    "## Train/Test Split\n",
    "target_col = 'two_year_recid'\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_model.drop([target_col], axis=1), \n",
    "                                                    data_model[target_col], \n",
    "                                                    stratify = data_model[target_col],\n",
    "                                                    random_state=42, test_size=0.2)\n",
    "model_w_race = classifier\n",
    "model_w_race.fit(X_train.values, y_train)\n",
    "\n",
    "# score for Black defendants\n",
    "X_test_ = X_test[ X_test['race_Caucasian']==0 ]\n",
    "y_test_ = y_test[ X_test['race_Caucasian']==0 ]\n",
    "y_pred_ = model_w_race.predict(X_test_.values)\n",
    "y_pred_= to_binary(y_pred_)\n",
    "[[tn , fp],[fn , tp]]  = confusion_matrix(y_test_, y_pred_)\n",
    "print(\"False positive rate (Black)      : \", fp/(fp+tn))\n",
    "print(\"False negative rate (Black)      : \", fn/(fn+tp))\n",
    "print(\"Accuracy (Black)      :  \", accuracy_score(y_test_, y_pred_) )\n",
    "print(\"AUC (Black)      :  \", roc_auc_score(y_test_, y_pred_) )\n",
    "\n",
    "fpr_black = fp/(fp+tn)\n",
    "fnr_black =  fn/(fn+tp)\n",
    "\n",
    "# score for White defendants\n",
    "X_test_ = X_test[ X_test['race_Caucasian']==1 ]\n",
    "y_test_ = y_test[ X_test['race_Caucasian']==1 ]\n",
    "y_pred_ = model_w_race.predict(X_test_.values)\n",
    "y_pred_= to_binary(y_pred_)\n",
    "[[tn , fp],[fn , tp]]  = confusion_matrix(y_test_, y_pred_)\n",
    "print(\"\\nFalse positive rate (White)      : \", fp/(fp+tn))\n",
    "print(\"False negative rate (White)      : \", fn/(fn+tp))\n",
    "print(\"Accuracy (White)      :  \", accuracy_score(y_test_, y_pred_) )\n",
    "print(\"AUC (White)      :  \", roc_auc_score(y_test_, y_pred_) )\n",
    "\n",
    "fpr_white = fp/(fp+tn)\n",
    "fnr_white =  fn/(fn+tp)\n",
    "\n",
    "print('\\nFalse positive rate Gap:', abs(fpr_black-fpr_white))\n",
    "print('False negative rate Gap:', abs(fnr_black-fnr_white))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model without 'race' (or unaware model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False positive rate (Black)      :  0.10571428571428572\n",
      "False negative rate (Black)      :  0.6462395543175488\n",
      "Accuracy (Black)      :   0.6205923836389281\n",
      "AUC (Black)      :   0.6240230799840827\n",
      "\n",
      "False positive rate (White)      :  0.20327868852459016\n",
      "False negative rate (White)      :  0.6267942583732058\n",
      "Accuracy (White)      :   0.6245136186770428\n",
      "AUC (White)      :   0.5849635265511021\n",
      "\n",
      "False positive rate Gap: 0.09756440281030444\n",
      "False negative rate Gap: 0.019445295944342966\n"
     ]
    }
   ],
   "source": [
    "## Train/Test Split\n",
    "target_col = 'two_year_recid'\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_model.drop([target_col], axis=1), \n",
    "                                                    data_model[target_col], \n",
    "                                                    stratify = data_model[target_col],\n",
    "                                                    random_state=42, test_size=0.2)\n",
    "\n",
    "cols = list(X_train.columns)\n",
    "cols.remove('race_Caucasian')\n",
    "X_train_wo_race = X_train[ cols ]\n",
    "X_test_wo_race = X_test[ cols ]\n",
    "\n",
    "model_wo_race = classifier\n",
    "model_wo_race.fit(X_train_wo_race.values, y_train)\n",
    "\n",
    "# score for Black defendants\n",
    "X_test_ = X_test_wo_race[ X_test['race_Caucasian']==0 ]\n",
    "y_test_ = y_test[ X_test['race_Caucasian']==0 ]\n",
    "y_pred_ = model_wo_race.predict(X_test_.values)\n",
    "y_pred_= to_binary(y_pred_)\n",
    "[[tn , fp],[fn , tp]]  = confusion_matrix(y_test_, y_pred_)\n",
    "print(\"False positive rate (Black)      : \", fp/(fp+tn))\n",
    "print(\"False negative rate (Black)      : \", fn/(fn+tp))\n",
    "print(\"Accuracy (Black)      :  \", accuracy_score(y_test_, y_pred_) )\n",
    "print(\"AUC (Black)      :  \", roc_auc_score(y_test_, y_pred_) )\n",
    "\n",
    "fpr_black = fp/(fp+tn)\n",
    "fnr_black =  fn/(fn+tp)\n",
    "\n",
    "# score for White defendants\n",
    "X_test_ = X_test_wo_race[ X_test['race_Caucasian']==1 ]\n",
    "y_test_ = y_test[ X_test['race_Caucasian']==1 ]\n",
    "y_pred_ = model_wo_race.predict(X_test_.values)\n",
    "y_pred_= to_binary(y_pred_)\n",
    "\n",
    "[[tn , fp],[fn , tp]]  = confusion_matrix(y_test_, y_pred_)\n",
    "print(\"\\nFalse positive rate (White)      : \", fp/(fp+tn))\n",
    "print(\"False negative rate (White)      : \", fn/(fn+tp))\n",
    "print(\"Accuracy (White)      :  \", accuracy_score(y_test_, y_pred_) )\n",
    "print(\"AUC (White)      :  \", roc_auc_score(y_test_, y_pred_) )\n",
    "\n",
    "fpr_white = fp/(fp+tn)\n",
    "fnr_white =  fn/(fn+tp)\n",
    "\n",
    "print('\\nFalse positive rate Gap:', abs(fpr_black-fpr_white))\n",
    "print('False negative rate Gap:', abs(fnr_black-fnr_white))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counterfactual Fairness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False positive rate (Black)      :  0.1\n",
      "False negative rate (Black)      :  0.6740947075208914\n",
      "Accuracy (Black)      :   0.609308885754584\n",
      "AUC (Black)      :   0.6129526462395544\n",
      "\n",
      "False positive rate (White)      :  0.16393442622950818\n",
      "False negative rate (White)      :  0.6507177033492823\n",
      "Accuracy (White)      :   0.6381322957198443\n",
      "AUC (White)      :   0.5926739352106047\n",
      "\n",
      "False positive rate Gap: 0.06393442622950818\n",
      "False negative rate Gap: 0.02337700417160915\n"
     ]
    }
   ],
   "source": [
    "# reference: https://github.com/fiorenza2/CFFair_Emulate\n",
    "## Train/Test Split\n",
    "target_col = 'two_year_recid'\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_model.drop([target_col], axis=1), \n",
    "                                                    data_model[target_col], \n",
    "                                                    stratify = data_model[target_col],\n",
    "                                                    random_state=42, test_size=0.2)\n",
    "\n",
    "\n",
    "non_race_feats = list(X_train.columns)\n",
    "non_race_feats.remove('race_Caucasian')\n",
    "\n",
    "eps_train = []\n",
    "eps_test = []\n",
    "for feat in non_race_feats:\n",
    "    model = classifier\n",
    "    model.fit(np.vstack((X_train['race_Caucasian'].values.reshape(-1,1),X_test['race_Caucasian'].values.reshape(-1,1))),\n",
    "               list(X_train[feat])  + list(X_test[feat]) \n",
    "                           )\n",
    "    v_train = list(X_train[feat]) - model.predict(X_train['race_Caucasian'].values.reshape(-1,1))\n",
    "    v_test = list(X_test[feat]) - model.predict(X_test['race_Caucasian'].values.reshape(-1,1))\n",
    "    eps_train += [ v_train.reshape(-1,1) ]\n",
    "    eps_test += [ v_test.reshape(-1,1) ]\n",
    "    \n",
    "# predict on target using abducted latents\n",
    "model = classifier\n",
    "model.fit(np.hstack( eps_train ),y_train)\n",
    "\n",
    "# predict on test epsilons\n",
    "preds = model.predict(np.hstack( eps_test ))\n",
    "preds= to_binary(preds)\n",
    "\n",
    "\n",
    "# score for Black defendants\n",
    "y_test_ = y_test[ X_test['race_Caucasian']==0 ]\n",
    "y_pred_ =  preds[ X_test['race_Caucasian']==0 ]\n",
    "[[tn , fp],[fn , tp]]  = confusion_matrix(y_test_, y_pred_)\n",
    "print(\"False positive rate (Black)      : \", fp/(fp+tn))\n",
    "print(\"False negative rate (Black)      : \", fn/(fn+tp))\n",
    "print(\"Accuracy (Black)      :  \", accuracy_score(y_test_, y_pred_) )\n",
    "print(\"AUC (Black)      :  \", roc_auc_score(y_test_, y_pred_) )\n",
    "\n",
    "fpr_black = fp/(fp+tn)\n",
    "fnr_black =  fn/(fn+tp)\n",
    "\n",
    "# score for White defendants\n",
    "y_test_ = y_test[ X_test['race_Caucasian']==1 ]\n",
    "y_pred_ =  preds[ X_test['race_Caucasian']==1 ]\n",
    "[[tn , fp],[fn , tp]]  = confusion_matrix(y_test_, y_pred_)\n",
    "print(\"\\nFalse positive rate (White)      : \", fp/(fp+tn))\n",
    "print(\"False negative rate (White)      : \", fn/(fn+tp))\n",
    "print(\"Accuracy (White)      :  \", accuracy_score(y_test_, y_pred_) )\n",
    "print(\"AUC (White)      :  \", roc_auc_score(y_test_, y_pred_) )\n",
    "\n",
    "fpr_white = fp/(fp+tn)\n",
    "fnr_white =  fn/(fn+tp)\n",
    "\n",
    "print('\\nFalse positive rate Gap:', abs(fpr_black-fpr_white))\n",
    "print('False negative rate Gap:', abs(fnr_black-fnr_white))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
